This project is the reimplementation of the paper [Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation](https://arxiv.org/abs/2509.12350)
# KGTB Model Training and Evaluation

This document provides instructions on how to train and evaluate the KGTB models.

## Dependencies

Install the required dependencies:

```bash
pip install -r requirements.txt
```

## Training

There are two main training scripts: `tokenizer_train.py` and `llm_train.py`.

### 1. Tokenizer Training

This script trains the KGTB model and generates the `stru_ids` files, which are then used by the LLM.

**Usage:**

```bash
python tokenizer_train.py
```

This will train the model for all locations (CA, NYC, TKY) and create the following files:

- `kgtb_model_{LOCATION}_best.pt`: The trained model for each location.
- `final_stru_ids_tensor_{LOCATION}.pt`: The final StruIDs tensor for each location.
- `stru_ids_{LOCATION}.json`: The mapping from entity IDs to StruIDs for each location.
- `quantizer_output/{LOCATION}/stru_ids/stru_id_epoch_{EPOCH}.json`: StruID mappings for each epoch.
- `quantizer_output/{LOCATION}/vectors/stru_id_epoch_{EPOCH}.pt`: StruID tensors for each epoch.

### 2. LLM Training

This script fine-tunes the language model using the prompts generated by `generate_prompts.py`.

**Prerequisites:**

Before running this script, you need to generate the prompts:

```bash
python generate_prompts.py
```

This will create `generated_prompts_{LOCATION}.jsonl` for each location.

**Usage:**

```bash
python llm_train.py --location [CA|NYC|TKY]
```

**Arguments:**

- `--location`: The dataset location (CA, NYC, or TKY). Default is `CA`.
- `--prompts_path`: Path to the generated prompts JSONL file. Defaults to `generated_prompts_{LOCATION}.jsonl`.
- `--output_dir`: Directory to save the fine-tuned model. Defaults to `./kgtb_llm_{LOCATION}_finetuned`.
- `--epochs`: Number of training epochs. Default is 8.
- `--learning_rate`: Learning rate. Default is 2e-4.

## Testing

There are two main testing scripts: `tokenizer_test.py` and `llm_test.py`.

### 1. Tokenizer Testing

This script evaluates the trained KGTB model on the test set and tests the generated `stru_ids` files.

**Usage:**

```bash
python tokenizer_test.py
```

### 2. LLM Testing

This script evaluates the fine-tuned language model.

**Usage:**

```bash
python llm_test.py --location [CA|NYC|TKY]
```

**Arguments:**

- `--location`: The dataset location (CA, NYC, or TKY).
- `--model_dir`: Path to the fine-tuned adapter/tokenizer directory. Defaults to `./kgtb_llm_{LOCATION}_finetuned`.
- `--output_dir`: Directory to write evaluation results. Default is `./kgtb_results`.
- `--max_eval_samples`: Maximum number of samples to evaluate. Default is 500.
